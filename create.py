import streamlit as st
from openai import OpenAI
import fitz  # PyMuPDF
from pptx import Presentation

st.set_page_config(page_title="AI ìê¸°ì†Œê°œì„œ ìƒì„±ê¸°", page_icon="ğŸ§‘â€ğŸ’¼")
st.title("ğŸ§‘â€ğŸ’¼ AI ìê¸°ì†Œê°œì„œ ì—ì„¸ì´ ìƒì„±ê¸°")

# ğŸ”‘ API í‚¤ ì…ë ¥
api_key = st.text_input("ğŸ”‘ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if not api_key:
    st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()
client = OpenAI(api_key=api_key)

# ê¸°ì—…ë³„ ì¸ì¬ìƒ
company_values = {
    "ì‚¼ì„±ì „ì": ["ë„ì „ì •ì‹ ", "ì°½ì˜ì„±", "ê¸€ë¡œë²Œ ì—­ëŸ‰"],
    "LGì „ì": ["ê³ ê°ì§€í–¥", "ììœ¨ê³¼ ì±…ì„", "ì§€ì†ì  í˜ì‹ "],
    "SKí•˜ì´ë‹‰ìŠ¤": ["íŒ¨ê¸°", "í˜‘ë ¥", "ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥"],
    "í˜„ëŒ€ìë™ì°¨": ["ë„ì „", "ì†Œí†µê³¼ í˜‘ì—…", "ê³ ê° ìµœìš°ì„ "],
    "ê¸°ì•„": ["í˜ì‹ ", "ì—´ì •", "ì†Œí†µ"],
    "ì¹´ì¹´ì˜¤": ["ìœ ì—°í•œ ì‚¬ê³ ", "ë¬¸ì œ í•´ê²°ë ¥", "ì†Œí†µ ëŠ¥ë ¥"],
    "ë„¤ì´ë²„": ["ê¸°ìˆ  ì¤‘ì‹¬", "ììœ¨ì„±", "ê¸€ë¡œë²Œ í™•ì¥"],
    "ë¡¯ë°": ["ë„ì „", "ì°½ì˜", "ì±…ì„ê°"],
    "í¬ìŠ¤ì½”": ["ê³ ê° ì¤‘ì‹¬", "ì°½ì˜ì™€ í˜ì‹ ", "ì‹ ë¢°ì™€ í˜‘ë ¥"],
    "CJ": ["ONLYONE ì •ì‹ ", "ì°½ì˜ì„±", "ì—´ì •"],
    "í•œí™”": ["ì‹ ë¢°", "ë„ì „", "í—Œì‹ "],
    "ëŒ€í•œí•­ê³µ": ["ì±…ì„ê°", "ì •ì§", "ê¸€ë¡œë²Œ ì—­ëŸ‰"],
    "KT": ["ë„ì „", "í˜ì‹ ", "ê³ ê°ê°€ì¹˜ ì¤‘ì‹¬"],
    "LGí™”í•™": ["ì±…ì„ê°", "í˜‘ì—…", "ì „ë¬¸ì„±"],
    "NHN": ["í˜‘ì—…", "ê¸°ìˆ  ì„±ì¥", "ìœ ì—°ì„±"],
    "ì¿ íŒ¡": ["ê³ ê° ì§‘ì°©", "ì†ë„", "ì†Œìœ  ì˜ì‹"],
    "í† ìŠ¤": ["ë¬¸ì œ í•´ê²° ì¤‘ì‹¬", "ì±…ì„", "ì‹ ì†í•œ ì‹¤í–‰"],
    "ë°°ë‹¬ì˜ë¯¼ì¡±(ìš°ì•„í•œí˜•ì œë“¤)": ["ììœ¨", "ìœ ì¾Œí•¨", "ì‚¬ìš©ì ì¤‘ì‹¬"],
    "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": ["ì •ì§", "í˜ì‹ ", "ì±…ì„ì˜ì‹"]
}

# ê¸°ì—… ì„ íƒ
company = st.selectbox("ğŸ“Œ ì§€ì›í•  ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš”", list(company_values.keys()))
if company:
    st.markdown(f"### ğŸ¢ {company}ì˜ ì¸ì¬ìƒ")
    for v in company_values[company]:
        st.markdown(f"- {v}")

# PDF/PPTX ì—…ë¡œë“œ
st.header("ğŸ“ PDF ë˜ëŠ” PPTX ì°¸ê³ ìë£Œ ì—…ë¡œë“œ (ì„ íƒ)")
uploaded_file = st.file_uploader("ìì†Œì„œ ì°¸ê³ ìš© íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf", "pptx"])

def extract_text_from_pdf(file):
    text = ""
    with fitz.open(stream=file.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text

def extract_text_from_pptx(file):
    prs = Presentation(file)
    text = ""
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text += shape.text + "\n"
    return text

pdf_text = ""
if uploaded_file:
    if uploaded_file.type == "application/pdf":
        pdf_text = extract_text_from_pdf(uploaded_file)
        st.success("âœ… PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ.")
    elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.presentationml.presentation":
        pdf_text = extract_text_from_pptx(uploaded_file)
        st.success("âœ… PPTXì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ.")
    else:
        st.error("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

# ìê¸°ì†Œê°œì„œ ì…ë ¥
st.header("ğŸ“ ìê¸°ì†Œê°œì„œ ì‘ì„± ì…ë ¥")
reason = st.text_area("1. ì§€ì› ë™ê¸°", height=100)
background = st.text_area("2. ì„±ì¥ ê³¼ì •", height=100)
experience = st.text_area("3. ì§ë¬´ ê´€ë ¨ ê²½í—˜", height=100)

# ìê¸°ì†Œê°œì„œ ìƒì„±
def generate_cover_letter(reason, background, experience, company, pdf_text=""):
    traits = ", ".join(company_values[company])
    prompt = f"""
ìì—°ìŠ¤ëŸ½ê³  ì§„ì†”í•œ ì—ì„¸ì´ í˜•ì‹ì˜ ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ê° í•­ëª©ì€ í•˜ë‚˜ì˜ ë¬¸ë‹¨ì´ë©°, ë¬¸ë‹¨ ê°„ ë¶€ë“œëŸ¬ìš´ ì—°ê²°ì´ ë˜ë„ë¡ ì‘ì„±í•´ ì£¼ì„¸ìš”.
[ì§€ì› ê¸°ì—…]: {company}
[ê¸°ì—… ì¸ì¬ìƒ]: {traits}

[ì§€ì› ë™ê¸°]
{reason}

[ì„±ì¥ ê³¼ì •]
{background}

[ì§ë¬´ ê²½í—˜]
{experience}
"""
    if pdf_text.strip():
        prompt += f"\n[PDF/PPTX ì°¸ê³  ë‚´ìš©]\n{pdf_text.strip()}\n"

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8
    )
    return response.choices[0].message.content.strip()

# ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
def generate_interview_questions(cover_letter_text, company):
    prompt = f"""
ë‹¤ìŒì€ {company}ì— ì§€ì›í•œ ìê¸°ì†Œê°œì„œì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë©´ì ‘ì—ì„œ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ì‹¬ë„ ìˆëŠ” ì§ˆë¬¸ 5ê°œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
[ìê¸°ì†Œê°œì„œ]
{cover_letter_text}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# ë©´ì ‘ ì—°ìŠµ ì±—ë´‡ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "current_question" not in st.session_state:
    st.session_state.current_question = ""

# ë²„íŠ¼: ìê¸°ì†Œê°œì„œ + ë©´ì ‘ ì§ˆë¬¸
if st.button("ğŸš€ ìê¸°ì†Œê°œì„œ + ë©´ì ‘ ì§ˆë¬¸ ìƒì„±"):
    if not (reason and background and experience):
        st.error("â— ëª¨ë“  ì…ë ¥ë€ì„ ì±„ì›Œì£¼ì„¸ìš”.")
    else:
        with st.spinner("ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            cover_letter = generate_cover_letter(reason, background, experience, company, pdf_text)
        st.subheader("ğŸ“„ ìƒì„±ëœ ìê¸°ì†Œê°œì„œ")
        st.write(cover_letter)
        st.download_button("ğŸ“¥ ìê¸°ì†Œê°œì„œ ë‹¤ìš´ë¡œë“œ", cover_letter, file_name="cover_letter.txt")

        with st.spinner("ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            interview_questions = generate_interview_questions(cover_letter, company)
        st.subheader("ğŸ’¬ ì˜ˆìƒ ë©´ì ‘ ì§ˆë¬¸")
        st.write(interview_questions)

        # ë©´ì ‘ ì±—ë´‡ ì´ˆê¸° ì§ˆë¬¸ ì„¤ì •
        st.session_state.cover_letter = cover_letter
        st.session_state.chat_history = []
        st.session_state.current_question = interview_questions.split('\n')[0]  # ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‚¬ìš©

# ë©´ì ‘ ì—°ìŠµ ì±—ë´‡
st.header("ğŸ¤– AI ë©´ì ‘ê´€ ì±—ë´‡ (ì—°ìŠµ ëª¨ë“œ)")
if st.session_state.current_question:
    st.markdown(f"**ğŸ§‘â€ğŸ’¼ ë©´ì ‘ê´€ ì§ˆë¬¸:** {st.session_state.current_question}")
    user_answer = st.text_input("ğŸ’¬ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", key="user_response")

    if st.button("ğŸ“¤ ë‹µë³€ ì œì¶œ"):
        st.session_state.chat_history.append(("ë©´ì ‘ê´€", st.session_state.current_question))
        st.session_state.chat_history.append(("ì§€ì›ì", user_answer))

        # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
        next_prompt = f"""
ë‹¤ìŒì€ ë©´ì ‘ ì—°ìŠµ ë‚´ìš©ì…ë‹ˆë‹¤.
[ìê¸°ì†Œê°œì„œ]: {st.session_state.cover_letter}
[ì´ì „ ì§ˆë¬¸]: {st.session_state.current_question}
[ì§€ì›ì ë‹µë³€]: {user_answer}

ë‹¤ìŒìœ¼ë¡œ ì´ì–´ì§ˆ ì‹¬í™” ì§ˆë¬¸ì„ 1ê°œ ìƒì„±í•´ ì£¼ì„¸ìš”. ì‹¤ì œ ë©´ì ‘ì²˜ëŸ¼ ë…¼ë¦¬ì  íë¦„ì´ ìˆê²Œ í•´ ì£¼ì„¸ìš”.
"""
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": next_prompt}],
            temperature=0.7
        )
        st.session_state.current_question = response.choices[0].message.content.strip()

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶œë ¥
if st.session_state.chat_history:
    st.subheader("ğŸ’¬ ë©´ì ‘ ì—°ìŠµ ê¸°ë¡")
    for role, msg in st.session_state.chat_history:
        st.markdown(f"**{role}**: {msg}")
